{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elZO6yxCOvwx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class LogicGate(tf.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.built = False\n",
        "\n",
        "    def __call__(self, x, train=True):\n",
        "        if not self.built:\n",
        "            input_dim = x.shape[-1]\n",
        "            hidden_dim = 2\n",
        "\n",
        "\n",
        "            self.w1 = tf.Variable(tf.random.normal([input_dim, hidden_dim]), name=\"hidden weights\")\n",
        "            self.b1 = tf.Variable(tf.zeros([hidden_dim]), name=\"hidden bias\")\n",
        "\n",
        "            self.w2 = tf.Variable(tf.random.normal([hidden_dim, 1]), name=\"output weights\")\n",
        "            self.b2 = tf.Variable(tf.zeros([1]), name=\"output bias\")\n",
        "\n",
        "            self.built = True\n",
        "\n",
        "        hidden = tf.sigmoid(tf.add(tf.matmul(x, self.w1), self.b1))\n",
        "        output = tf.sigmoid(tf.add(tf.matmul(hidden, self.w2), self.b2))\n",
        "        return output\n",
        "\n",
        "def compute_loss(y_pred, y_true):\n",
        "    epsilon = 1e-7\n",
        "    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
        "    return -tf.reduce_mean(y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
        "\n",
        "def train_model(model, x_train, y_train, learning_rate=0.1, epochs=6000):\n",
        "    for epoch in range(epochs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(x_train)\n",
        "            loss = compute_loss(y_pred, y_train)\n",
        "\n",
        "        grads = tape.gradient(loss, model.variables)\n",
        "        for g, v in zip(grads, model.variables):\n",
        "            v.assign_sub(learning_rate * g)\n",
        "\n",
        "        if epoch % 1000 == 0:\n",
        "            acc = compute_accuracy(model, x_train, y_train)\n",
        "            print(f\"Epoch {epoch}, Loss: {loss.numpy():.4f}, Accuracy: {acc:.4f}\")\n",
        "\n",
        "def compute_accuracy(model, x, y_true):\n",
        "    y_pred = model(x, train=False)\n",
        "    y_pred_rounded = tf.round(y_pred)\n",
        "    correct = tf.equal(y_pred_rounded, y_true)\n",
        "    return tf.reduce_mean(tf.cast(correct, tf.float32)).numpy()\n"
      ],
      "metadata": {
        "id": "fAS91ibeOy0W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "xor_table = np.array([[0, 0, 0],\n",
        "                      [0, 1, 1],\n",
        "                      [1, 0, 1],\n",
        "                      [1, 1, 0]], dtype=np.float32)\n",
        "\n",
        "x_train = xor_table[:, :2]\n",
        "y_train = xor_table[:, 2:]\n",
        "\n",
        "model = LogicGate()\n",
        "train_model(model, x_train, y_train)\n",
        "\n",
        "w1 = model.w1.numpy()\n",
        "b1 = model.b1.numpy()\n",
        "w2 = model.w2.numpy()\n",
        "b2 = model.b2.numpy()\n",
        "\n",
        "print(f\"Hidden Layer Weights (w1): \\n{w1}\")\n",
        "print(f\"Hidden Layer Bias (b1): \\n{b1}\")\n",
        "print(f\"Output Layer Weights (w2): \\n{w2}\")\n",
        "print(f\"Output Layer Bias (b2): \\n{b2}\\n\")\n",
        "\n",
        "y_pred = model(x_train, train=False).numpy().round().astype(np.uint8)\n",
        "print(\"Predicted Truth Table:\")\n",
        "print(np.column_stack((xor_table[:, :2], y_pred)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLm5q9SDO3gE",
        "outputId": "0d38c67a-dc37-4fd9-865f-76bae2f01cb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7005, Accuracy: 0.5000\n",
            "Epoch 1000, Loss: 0.6478, Accuracy: 0.5000\n",
            "Epoch 2000, Loss: 0.4644, Accuracy: 0.7500\n",
            "Epoch 3000, Loss: 0.1412, Accuracy: 1.0000\n",
            "Epoch 4000, Loss: 0.0646, Accuracy: 1.0000\n",
            "Epoch 5000, Loss: 0.0404, Accuracy: 1.0000\n",
            "Hidden Layer Weights (w1): \n",
            "[[ 5.867798 -5.50227 ]\n",
            " [-6.042031  5.181547]]\n",
            "Hidden Layer Bias (b1): \n",
            "[-3.307535 -2.862797]\n",
            "Output Layer Weights (w2): \n",
            "[[8.383733]\n",
            " [8.439888]]\n",
            "Output Layer Bias (b2): \n",
            "[-4.1069164]\n",
            "\n",
            "Predicted Truth Table:\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 1.]\n",
            " [1. 0. 1.]\n",
            " [1. 1. 0.]]\n"
          ]
        }
      ]
    }
  ]
}